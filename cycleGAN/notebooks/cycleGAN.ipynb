{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import re\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport tensorflow_addons as tfa\nfrom tensorflow.keras.layers import Layer\n\nfrom kaggle_datasets import KaggleDatasets\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-31T14:16:50.193089Z","iopub.execute_input":"2023-10-31T14:16:50.193367Z","iopub.status.idle":"2023-10-31T14:16:58.791283Z","shell.execute_reply.started":"2023-10-31T14:16:50.193320Z","shell.execute_reply":"2023-10-31T14:16:58.790249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# try:\n#     tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n#     print('Device:', tpu.master())\n#     tf.config.experimental_connect_to_cluster(tpu)\n#     tf.tpu.experimental.initialize_tpu_system(tpu)\n#     strategy = tf.distribute.experimental.TPUStrategy(tpu)\n# except:\n#     strategy = tf.distribute.get_strategy()\n# print('Number of replicas:', strategy.num_replicas_in_sync)\n\n# AUTOTUNE = tf.data.experimental.AUTOTUNE\n    \n# print(tf.__version__)\n\n\n\n\n\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n    print('Device:', tpu.master())\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nexcept:\n    strategy = tf.distribute.get_strategy()\nprint('Number of replicas:', strategy.num_replicas_in_sync)\n\nAUTOTUNE = tf.data.experimental.AUTOTUNE\n    \nprint(tf.__version__)","metadata":{"execution":{"iopub.status.busy":"2023-10-31T14:16:58.793526Z","iopub.execute_input":"2023-10-31T14:16:58.794452Z","iopub.status.idle":"2023-10-31T14:16:58.808116Z","shell.execute_reply.started":"2023-10-31T14:16:58.794406Z","shell.execute_reply":"2023-10-31T14:16:58.807060Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 95\n# EPOCHS = 1\n# EPOCHS = 60\nSIZE = 256\nSIZE_RESIZE = 128\n# SIZE = SIZE_RESIZE = 128\n# SIZE = SIZE_RESIZE = 256\n\n\n# BATCH_SIZE = 16\n# BATCH_SIZE = 40\nBATCH_SIZE = 24\n# BATCH_SIZE = 8","metadata":{"execution":{"iopub.status.busy":"2023-10-31T14:16:58.809329Z","iopub.execute_input":"2023-10-31T14:16:58.809707Z","iopub.status.idle":"2023-10-31T14:16:58.814934Z","shell.execute_reply.started":"2023-10-31T14:16:58.809673Z","shell.execute_reply":"2023-10-31T14:16:58.813893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def data_augment(image):\n    p_spatial = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_rotate = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_random_crop = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    \n    if p_rotate > .8:\n        image = tf.image.rot90(image, k=3) \n    elif p_rotate > .6:\n        image = tf.image.rot90(image, k=2) \n    elif p_rotate > .4:\n        image = tf.image.rot90(image, k=1)\n        \n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_flip_up_down(image)\n    if p_spatial > .75:\n        image = tf.image.transpose(image)\n    image = tf.image.random_crop(image, size=[SIZE_RESIZE, SIZE_RESIZE, 3])\n    return image\n\nIMAGE_SIZE = [SIZE, SIZE]\n\ndef decode_image(image):\n    image = tf.image.decode_jpeg(image, channels=3)\n    image = (tf.cast(image, tf.float32) / 127.5) - 1\n#     image = tf.reshape(image, [*IMAGE_SIZE, 3])\n    image = tf.image.resize(image,[SIZE, SIZE])\n    return image\n\ndef read_tfrecord(example):\n    tfrecord_format = {\n        \"image\": tf.io.FixedLenFeature([], tf.string),\n    }\n    example = tf.io.parse_single_example(example, tfrecord_format)\n    image = decode_image(example[\"image\"])\n    return image\n\ndef load_dataset(filenames, apply_jitter=False, repeat=True, shuffle=True, batch_size=BATCH_SIZE):\n    dataset = tf.data.TFRecordDataset(filenames)\n    dataset = dataset.map(read_tfrecord)\n    \n    if apply_jitter:\n        dataset = dataset.map(data_augment)\n            \n    if repeat:\n        dataset = dataset.repeat()\n    if shuffle:\n        dataset = dataset.shuffle(512)\n        \n    dataset = dataset.batch(batch_size)\n#     dataset = dataset.cache()\n#     dataset = dataset.prefetch(AUTOTUNE)\n    \n    return dataset","metadata":{"execution":{"iopub.status.busy":"2023-10-31T14:16:58.817051Z","iopub.execute_input":"2023-10-31T14:16:58.817396Z","iopub.status.idle":"2023-10-31T14:16:58.831192Z","shell.execute_reply.started":"2023-10-31T14:16:58.817317Z","shell.execute_reply":"2023-10-31T14:16:58.830393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Figuring out data transfer to make the entire ting work :)","metadata":{}},{"cell_type":"code","source":"# \"/kaggle/input/cyclegan-pws-new2/*.tfrecords\" \n# \"/kaggle/input/cyclegan-pws-new/human-faces-images-tfrecord/*.tfrecords\"\n# \"/kaggle/input/cyclegan-pws-new/pws-images-tfrecord/*.tfrecords\"\n\nHUMAN_FACES_p1 = tf.io.gfile.glob(\"/kaggle/input/cyclegan-pws-new2/*.tfrecords\" )\nHUMAN_FACES_p2 = tf.io.gfile.glob(\"/kaggle/input/cyclegan-pws-new/human-faces-images-tfrecord/*.tfrecords\")\nHUMAN_FACES = HUMAN_FACES_p1 + HUMAN_FACES_p2\nPWS_FACES = tf.io.gfile.glob(\"/kaggle/input/pws-images-no-ambroziak-tfrecord/*.tfrecords\")\n\n\nhuman_ds = load_dataset(HUMAN_FACES, apply_jitter=True)\npws_ds = load_dataset(PWS_FACES, apply_jitter=True)\n\n# human_ds_test = load_dataset(HUMAN_FACES, apply_jitter=False, repeat=False, shuffle=False, batch_size=1)\npws_ds_test = load_dataset(PWS_FACES, apply_jitter=False, repeat=False, shuffle=False, batch_size=1)\n\nexample_human = next(iter(human_ds))\nplt.subplot(121)\nplt.title('Normal Face')\nplt.imshow(example_human[0] * 0.5 + 0.5)\n\n\nexample_pws = next(iter(pws_ds))\nplt.subplot(122)\nplt.title('PWS Face')\nplt.imshow(example_pws[0] * 0.5 + 0.5)","metadata":{"execution":{"iopub.status.busy":"2023-10-31T14:16:58.832243Z","iopub.execute_input":"2023-10-31T14:16:58.832535Z","iopub.status.idle":"2023-10-31T14:17:18.377335Z","shell.execute_reply.started":"2023-10-31T14:16:58.832511Z","shell.execute_reply":"2023-10-31T14:17:18.376398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def count_data_items(filenames):\n#     n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n#     return np.sum(n)\n\n# n_pws_samples = count_data_items(PWS_FACES)\n# n_human_samples = count_data_items(HUMAN_FACES)\n\n# print(f\"n_pws_samples:{n_pws_samples}\")\n# print(f\"n_human_samples:{n_human_samples}\")\n\nn_pws_samples = 166\nn_human_samples = 6973","metadata":{"execution":{"iopub.status.busy":"2023-10-31T14:17:18.378333Z","iopub.execute_input":"2023-10-31T14:17:18.378620Z","iopub.status.idle":"2023-10-31T14:17:18.383697Z","shell.execute_reply.started":"2023-10-31T14:17:18.378594Z","shell.execute_reply":"2023-10-31T14:17:18.382759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def DiffAugment(x, policy='', channels_first=False):\n    if policy:\n        if channels_first:\n            x = tf.transpose(x, [0, 2, 3, 1])\n        for p in policy.split(','):\n            for f in AUGMENT_FNS[p]:\n                x = f(x)\n        if channels_first:\n            x = tf.transpose(x, [0, 3, 1, 2])\n    return x\n\n\ndef rand_brightness(x):\n    magnitude = tf.random.uniform([tf.shape(x)[0], 1, 1, 1]) - 0.5\n    x = x + magnitude\n    return x\n\n\ndef rand_saturation(x):\n    magnitude = tf.random.uniform([tf.shape(x)[0], 1, 1, 1]) * 2\n    x_mean = tf.reduce_mean(x, axis=3, keepdims=True)\n    x = (x - x_mean) * magnitude + x_mean\n    return x\n\n\ndef rand_contrast(x):\n    magnitude = tf.random.uniform([tf.shape(x)[0], 1, 1, 1]) + 0.5\n    x_mean = tf.reduce_mean(x, axis=[1, 2, 3], keepdims=True)\n    x = (x - x_mean) * magnitude + x_mean\n    return x\n\n\ndef rand_translation(x, ratio=0.125):\n    batch_size = tf.shape(x)[0]\n    image_size = tf.shape(x)[1:3]\n    shift = tf.cast(tf.cast(image_size, tf.float32) * ratio + 0.5, tf.int32)\n    translation_x = tf.random.uniform([batch_size, 1], -shift[0], shift[0] + 1, dtype=tf.int32)\n    translation_y = tf.random.uniform([batch_size, 1], -shift[1], shift[1] + 1, dtype=tf.int32)\n    grid_x = tf.clip_by_value(tf.expand_dims(tf.range(image_size[0], dtype=tf.int32), 0) + translation_x + 1, 0, image_size[0] + 1)\n    grid_y = tf.clip_by_value(tf.expand_dims(tf.range(image_size[1], dtype=tf.int32), 0) + translation_y + 1, 0, image_size[1] + 1)\n    x = tf.gather_nd(tf.pad(x, [[0, 0], [1, 1], [0, 0], [0, 0]]), tf.expand_dims(grid_x, -1), batch_dims=1)\n    x = tf.transpose(tf.gather_nd(tf.pad(tf.transpose(x, [0, 2, 1, 3]), [[0, 0], [1, 1], [0, 0], [0, 0]]), tf.expand_dims(grid_y, -1), batch_dims=1), [0, 2, 1, 3])\n    return x\n\n\ndef rand_cutout(x, ratio=0.5):\n    batch_size = tf.shape(x)[0]\n    image_size = tf.shape(x)[1:3]\n    cutout_size = tf.cast(tf.cast(image_size, tf.float32) * ratio + 0.5, tf.int32)\n    offset_x = tf.random.uniform([tf.shape(x)[0], 1, 1], maxval=image_size[0] + (1 - cutout_size[0] % 2), dtype=tf.int32)\n    offset_y = tf.random.uniform([tf.shape(x)[0], 1, 1], maxval=image_size[1] + (1 - cutout_size[1] % 2), dtype=tf.int32)\n    grid_batch, grid_x, grid_y = tf.meshgrid(tf.range(batch_size, dtype=tf.int32), tf.range(cutout_size[0], dtype=tf.int32), tf.range(cutout_size[1], dtype=tf.int32), indexing='ij')\n    cutout_grid = tf.stack([grid_batch, grid_x + offset_x - cutout_size[0] // 2, grid_y + offset_y - cutout_size[1] // 2], axis=-1)\n    mask_shape = tf.stack([batch_size, image_size[0], image_size[1]])\n    cutout_grid = tf.maximum(cutout_grid, 0)\n    cutout_grid = tf.minimum(cutout_grid, tf.reshape(mask_shape - 1, [1, 1, 1, 3]))\n    mask = tf.maximum(1 - tf.scatter_nd(cutout_grid, tf.ones([batch_size, cutout_size[0], cutout_size[1]], dtype=tf.float32), mask_shape), 0)\n    x = x * tf.expand_dims(mask, axis=3)\n    return x\n\n\nAUGMENT_FNS = {\n    'color': [rand_brightness, rand_saturation, rand_contrast],\n    'translation': [rand_translation],\n    'cutout': [rand_cutout],\n}\n\ndef aug_fn(image):\n    return DiffAugment(image,\"translation,cutout\")","metadata":{"execution":{"iopub.status.busy":"2023-10-31T14:17:18.384993Z","iopub.execute_input":"2023-10-31T14:17:18.385228Z","iopub.status.idle":"2023-10-31T14:17:18.410036Z","shell.execute_reply.started":"2023-10-31T14:17:18.385206Z","shell.execute_reply":"2023-10-31T14:17:18.409116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Designing Model's architecture\n### ResNet Generator","metadata":{"execution":{"iopub.status.busy":"2023-09-27T19:42:24.884150Z","iopub.execute_input":"2023-09-27T19:42:24.885022Z","iopub.status.idle":"2023-09-27T19:42:25.268841Z","shell.execute_reply.started":"2023-09-27T19:42:24.884965Z","shell.execute_reply":"2023-09-27T19:42:25.267426Z"}}},{"cell_type":"code","source":"def Downsample(X, filter_count, kernel_size, padding, stride, apply_norm=True):\n    initializer = tf.random_normal_initializer(0., 0.02)\n    gamma_init = keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n    \n    X = tf.keras.layers.ZeroPadding2D((padding,padding))(X)\n    X = tf.keras.layers.Conv2D(filter_count, (kernel_size,kernel_size), padding='valid', strides=(stride,stride), \n                                      kernel_initializer=initializer, use_bias=False)(X)\n    \n    if apply_norm:\n        X = tfa.layers.InstanceNormalization(gamma_initializer=gamma_init)(X)\n    \n    X = tf.keras.layers.LeakyReLU()(X)\n    \n    return X\n\ndef Upsample(X, filter_count, kernel_size, stride, activation='relu', apply_norm=True):\n    initializer = tf.random_normal_initializer(0., 0.02)\n    gamma_init = keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n\n    X = tf.keras.layers.Conv2DTranspose(filter_count, (kernel_size,kernel_size), padding='same', strides=(stride,stride), \n                                        kernel_initializer=initializer, use_bias=False)(X)\n    \n    if apply_norm:\n        X = tfa.layers.InstanceNormalization(gamma_initializer=gamma_init)(X)\n        \n    X = tf.keras.layers.Activation(activation)(X)\n    \n    return X\n\ndef ResidualBlock(X):\n    initializer = tf.random_normal_initializer(0., 0.02)\n    gamma_init = keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n    \n    X_shortcut = X\n    \n    # Layer 1   \n    X = tf.keras.layers.ZeroPadding2D((1,1))(X)\n    X = tf.keras.layers.Conv2D(256, (3,3), padding='valid', strides=(1,1), kernel_initializer=initializer, use_bias=False)(X)\n    X = tfa.layers.InstanceNormalization(gamma_initializer=gamma_init)(X)\n    X = tf.keras.layers.Activation('relu')(X)\n    \n    # Layer 2  \n    X = tf.keras.layers.ZeroPadding2D((1,1))(X)\n    X = tf.keras.layers.Conv2D(256, (3,3), padding='valid', strides=(1,1), kernel_initializer=initializer, use_bias=False)(X)\n    X = tfa.layers.InstanceNormalization(gamma_initializer=gamma_init)(X)\n    \n    X = tf.keras.layers.Add()([X, X_shortcut])\n    X = tf.keras.layers.Activation('relu')(X)\n    \n    return X\n\ndef ResNetGenerator(height=SIZE, width=SIZE):\n    initializer = tf.random_normal_initializer(0., 0.02)\n    gamma_init = keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n    \n    X_input = tf.keras.layers.Input((height, width, 3))\n    \n    skips = []\n    \n    X = Downsample(X_input, 64, 7, 3, 1, apply_norm=False)\n    skips.append(X)\n    \n    X = Downsample(X, 128, 3, 1, 2)\n    skips.append(X)\n    \n    X = Downsample(X, 256, 3, 1, 2)\n    \n    X = ResidualBlock(X)\n    X = ResidualBlock(X)\n    X = ResidualBlock(X)\n    X = ResidualBlock(X)\n    X = ResidualBlock(X)\n    X = ResidualBlock(X)\n    #X = ResidualBlock(X)\n    #X = ResidualBlock(X)\n    #X = ResidualBlock(X)\n    \n    skips = list(reversed(skips))\n        \n    X = Upsample(X, 128, 4, 2)\n    X = tf.keras.layers.Concatenate()([X, skips[0]])\n    \n    X = Upsample(X, 64, 4, 2)\n    X = tf.keras.layers.Concatenate()([X, skips[1]])\n    \n    X = Upsample(X, 3, 7, 1, activation='tanh', apply_norm=False)\n    \n    model = tf.keras.models.Model(inputs=X_input, outputs=X)\n\n    return model\n\n# generator = ResNetGenerator()\n# generator.summary()","metadata":{"execution":{"iopub.status.busy":"2023-10-31T14:17:18.411042Z","iopub.execute_input":"2023-10-31T14:17:18.411320Z","iopub.status.idle":"2023-10-31T14:17:18.431556Z","shell.execute_reply.started":"2023-10-31T14:17:18.411295Z","shell.execute_reply":"2023-10-31T14:17:18.430738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### PatchGAN Discriminator","metadata":{}},{"cell_type":"code","source":"def Discriminator(height=SIZE, width=SIZE):\n    initializer = tf.random_normal_initializer(0., 0.02)\n    gamma_init = keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n    \n    X_input = tf.keras.layers.Input((height, width, 3))\n\n    X = Downsample(X_input, 64, 4, 1, 2, apply_norm=False)\n    X = Downsample(X, 128, 4, 1, 2)\n    X = Downsample(X, 256, 4, 1, 2)\n    X = Downsample(X, 512, 4, 1, 1)\n    \n    X = tf.keras.layers.ZeroPadding2D()(X)\n    X = tf.keras.layers.Conv2D(1, (4,4), padding='valid', strides=(1,1), kernel_initializer=initializer, use_bias=False)(X)   \n    X = tf.keras.layers.Activation('sigmoid')(X)\n    \n    model = tf.keras.models.Model(inputs=X_input, outputs=X)\n\n    return model\n\n\n\n# def Discriminator(height=SIZE, width=SIZE):\n#     initializer = tf.random_normal_initializer(0., 0.02)\n#     gamma_init = keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n    \n#     X_input = tf.keras.layers.Input((height, width, 3))\n\n#     X = Downsample(X_input, 64, 4, 1, 2, apply_norm=False)\n#     X = Downsample(X, 128, 4, 1, 2)\n#     X = Downsample(X, 256, 4, 1, 2)\n#     X = Downsample(X, 512, 4, 1, 1)\n    \n#     X = tf.keras.layers.ZeroPadding2D()(X)\n#     X = tf.keras.layers.Conv2D(1, (4,4), padding='valid', strides=(1,1), kernel_initializer=initializer, use_bias=False)(X)   \n# #     X = tf.keras.layers.Activation('sigmoid')(X)\n\n#     # new stuff\n#     X = tf.keras.layers.Dropout(0.3)(X)\n#     X = tf.keras.layers.Flatten()(X)\n#     X = tf.keras.layers.Dense(1)(X)\n#     X = tf.keras.layers.Activation('sigmoid')(X)\n    \n#     model = tf.keras.models.Model(inputs=X_input, outputs=X)\n\n#     return model\n\n# discriminator = Discriminator()\n# discriminator.summary()","metadata":{"execution":{"iopub.status.busy":"2023-10-31T14:17:18.432811Z","iopub.execute_input":"2023-10-31T14:17:18.433174Z","iopub.status.idle":"2023-10-31T14:17:18.448189Z","shell.execute_reply.started":"2023-10-31T14:17:18.433142Z","shell.execute_reply":"2023-10-31T14:17:18.447290Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with strategy.scope():\n    monet_generator = ResNetGenerator(height=None, width=None) # transforms photos to Monet-esque paintings\n    photo_generator = ResNetGenerator(height=None, width=None) # transforms Monet paintings to be more like photos\n\n    monet_discriminator = Discriminator(height=None, width=None) # differentiates real Monet paintings and generated Monet paintings\n    photo_discriminator = Discriminator(height=None, width=None) # differentiates real photos and generated photos\n\n#     monet_generator = ResNetGenerator(height=SIZE, width=SIZE) # transforms photos to Monet-esque paintings\n#     photo_generator = ResNetGenerator(height=SIZE, width=SIZE) # transforms Monet paintings to be more like photos\n\n#     monet_discriminator = Discriminator(height=SIZE, width=SIZE) # differentiates real Monet paintings and generated Monet paintings\n#     photo_discriminator = Discriminator(height=SIZE, width=SIZE) # differentiates real photos and generated photos","metadata":{"execution":{"iopub.status.busy":"2023-10-31T14:17:18.452754Z","iopub.execute_input":"2023-10-31T14:17:18.453031Z","iopub.status.idle":"2023-10-31T14:17:20.990650Z","shell.execute_reply.started":"2023-10-31T14:17:18.453006Z","shell.execute_reply":"2023-10-31T14:17:20.989829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CycleGan(keras.Model):\n    def __init__(\n        self,\n        monet_generator,\n        photo_generator,\n        monet_discriminator,\n        photo_discriminator,\n        lambda_cycle=10,\n    ):\n        super(CycleGan, self).__init__()\n        self.m_gen = monet_generator\n        self.p_gen = photo_generator\n        self.m_disc = monet_discriminator\n        self.p_disc = photo_discriminator\n        self.lambda_cycle = lambda_cycle\n        \n    def compile(\n        self,\n        m_gen_optimizer,\n        p_gen_optimizer,\n        m_disc_optimizer,\n        p_disc_optimizer,\n        gen_loss_fn,\n        disc_loss_fn,\n        cycle_loss_fn,\n        identity_loss_fn\n    ):\n        super(CycleGan, self).compile()\n        self.m_gen_optimizer = m_gen_optimizer\n        self.p_gen_optimizer = p_gen_optimizer\n        self.m_disc_optimizer = m_disc_optimizer\n        self.p_disc_optimizer = p_disc_optimizer\n        self.gen_loss_fn = gen_loss_fn\n        self.disc_loss_fn = disc_loss_fn\n        self.cycle_loss_fn = cycle_loss_fn\n        self.identity_loss_fn = identity_loss_fn\n        \n    def train_step(self, batch_data):\n        real_monet, real_photo = batch_data\n        \n        with tf.GradientTape(persistent=True) as tape:\n            # photo to monet back to photo\n            fake_monet = self.m_gen(real_photo, training=True)\n            cycled_photo = self.p_gen(fake_monet, training=True)\n\n            # monet to photo back to monet\n            fake_photo = self.p_gen(real_monet, training=True)\n            cycled_monet = self.m_gen(fake_photo, training=True)\n\n            # generating itself\n            same_monet = self.m_gen(real_monet, training=True)\n            same_photo = self.p_gen(real_photo, training=True)\n\n            # Diff Augmentation Start\n            both_monet = tf.concat([real_monet, fake_monet], axis=0)      \n            both_photo = tf.concat([real_photo, fake_photo], axis=0)            \n            \n            aug_monet = aug_fn(both_monet)\n            aug_photo = aug_fn(both_photo)\n            \n            aug_real_monet, aug_fake_monet = tf.split(aug_monet, num_or_size_splits=2, axis=0)\n            aug_real_photo, aug_fake_photo = tf.split(aug_photo, num_or_size_splits=2, axis=0)\n            # Diff Augmentation End\n            \n            # discriminator used to check, inputing real images\n            disc_real_monet = self.m_disc(aug_real_monet, training=True)\n            disc_real_photo = self.p_disc(aug_real_photo, training=True)\n\n            # discriminator used to check, inputing fake images\n            disc_fake_monet = self.m_disc(aug_fake_monet, training=True)\n            disc_fake_photo = self.p_disc(aug_fake_photo, training=True)\n\n            # evaluates generator loss\n            monet_gen_loss = self.gen_loss_fn(disc_fake_monet)\n            photo_gen_loss = self.gen_loss_fn(disc_fake_photo)\n\n            # evaluates total cycle consistency loss\n            total_cycle_loss = self.cycle_loss_fn(real_monet, cycled_monet, self.lambda_cycle) + self.cycle_loss_fn(real_photo, cycled_photo, self.lambda_cycle)\n#             total_cycle_loss = 1.5 * (self.cycle_loss_fn(real_monet, cycled_monet, self.lambda_cycle) + self.cycle_loss_fn(real_photo, cycled_photo, self.lambda_cycle))\n\n            # evaluates total generator loss\n            total_monet_gen_loss = monet_gen_loss + total_cycle_loss + self.identity_loss_fn(real_monet, same_monet, self.lambda_cycle)\n            total_photo_gen_loss = photo_gen_loss + total_cycle_loss + self.identity_loss_fn(real_photo, same_photo, self.lambda_cycle)\n\n            # evaluates discriminator loss\n            monet_disc_loss = self.disc_loss_fn(disc_real_monet, disc_fake_monet)\n            photo_disc_loss = self.disc_loss_fn(disc_real_photo, disc_fake_photo)\n\n        # Calculate the gradients for generator and discriminator\n        monet_generator_gradients = tape.gradient(total_monet_gen_loss,\n                                                  self.m_gen.trainable_variables)\n        photo_generator_gradients = tape.gradient(total_photo_gen_loss,\n                                                  self.p_gen.trainable_variables)\n\n        monet_discriminator_gradients = tape.gradient(monet_disc_loss,\n                                                      self.m_disc.trainable_variables)\n        photo_discriminator_gradients = tape.gradient(photo_disc_loss,\n                                                      self.p_disc.trainable_variables)\n\n        # Apply the gradients to the optimizer\n        self.m_gen_optimizer.apply_gradients(zip(monet_generator_gradients,\n                                                 self.m_gen.trainable_variables))\n\n        self.p_gen_optimizer.apply_gradients(zip(photo_generator_gradients,\n                                                 self.p_gen.trainable_variables))\n\n        self.m_disc_optimizer.apply_gradients(zip(monet_discriminator_gradients,\n                                                  self.m_disc.trainable_variables))\n\n        self.p_disc_optimizer.apply_gradients(zip(photo_discriminator_gradients,\n                                                  self.p_disc.trainable_variables))\n        \n        return {\n            \"monet_gen_loss\": total_monet_gen_loss,\n            \"photo_gen_loss\": total_photo_gen_loss,\n            \"monet_disc_loss\": monet_disc_loss,\n            \"photo_disc_loss\": photo_disc_loss\n        }","metadata":{"execution":{"iopub.status.busy":"2023-10-31T14:17:20.991964Z","iopub.execute_input":"2023-10-31T14:17:20.992224Z","iopub.status.idle":"2023-10-31T14:17:21.014107Z","shell.execute_reply.started":"2023-10-31T14:17:20.992198Z","shell.execute_reply":"2023-10-31T14:17:21.013151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with strategy.scope():\n    def discriminator_loss(real, generated):\n        real_loss = tf.keras.losses.BinaryCrossentropy(from_logits=False, reduction=tf.keras.losses.Reduction.NONE)(tf.ones_like(real), real)\n\n        generated_loss = tf.keras.losses.BinaryCrossentropy(from_logits=False, reduction=tf.keras.losses.Reduction.NONE)(tf.zeros_like(generated), generated)\n\n        total_disc_loss = real_loss + generated_loss\n\n        return total_disc_loss * 0.5","metadata":{"execution":{"iopub.status.busy":"2023-10-31T14:17:21.015511Z","iopub.execute_input":"2023-10-31T14:17:21.015880Z","iopub.status.idle":"2023-10-31T14:17:21.035075Z","shell.execute_reply.started":"2023-10-31T14:17:21.015845Z","shell.execute_reply":"2023-10-31T14:17:21.034124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with strategy.scope():\n    def generator_loss(generated):\n        return tf.keras.losses.BinaryCrossentropy(from_logits=False, reduction=tf.keras.losses.Reduction.NONE)(tf.ones_like(generated), generated)","metadata":{"execution":{"iopub.status.busy":"2023-10-31T14:17:21.036203Z","iopub.execute_input":"2023-10-31T14:17:21.036497Z","iopub.status.idle":"2023-10-31T14:17:21.049814Z","shell.execute_reply.started":"2023-10-31T14:17:21.036471Z","shell.execute_reply":"2023-10-31T14:17:21.049093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with strategy.scope():\n    def calc_cycle_loss(real_image, cycled_image, LAMBDA):\n        loss1 = tf.reduce_mean(tf.abs(real_image - cycled_image))\n\n        return LAMBDA * loss1","metadata":{"execution":{"iopub.status.busy":"2023-10-31T14:17:21.050866Z","iopub.execute_input":"2023-10-31T14:17:21.051175Z","iopub.status.idle":"2023-10-31T14:17:21.060113Z","shell.execute_reply.started":"2023-10-31T14:17:21.051109Z","shell.execute_reply":"2023-10-31T14:17:21.059206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with strategy.scope():\n    def identity_loss(real_image, same_image, LAMBDA):\n        loss = tf.reduce_mean(tf.abs(real_image - same_image))\n        return LAMBDA * 0.5 * loss","metadata":{"execution":{"iopub.status.busy":"2023-10-31T14:17:21.061281Z","iopub.execute_input":"2023-10-31T14:17:21.061610Z","iopub.status.idle":"2023-10-31T14:17:21.075306Z","shell.execute_reply.started":"2023-10-31T14:17:21.061582Z","shell.execute_reply":"2023-10-31T14:17:21.074326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@tf.function\ndef linear_schedule_with_warmup(step):\n    \"\"\" Create a schedule with a learning rate that decreases linearly after\n    linearly increasing during a warmup period.\n    \"\"\"\n    lr_start   = 2e-4\n    lr_max     = 2e-4\n    lr_min     = 0.\n    \n    steps_per_epoch = int(max(n_pws_samples, n_human_samples)//BATCH_SIZE)\n    total_steps = EPOCHS * steps_per_epoch\n    warmup_steps = 1\n    hold_max_steps = total_steps * 0.8\n    \n    if step < warmup_steps:\n        lr = (lr_max - lr_start) / warmup_steps * step + lr_start\n    elif step < warmup_steps + hold_max_steps:\n        lr = lr_max\n    else:\n        lr = lr_max * ((total_steps - step) / (total_steps - warmup_steps - hold_max_steps))\n        if lr_min is not None:\n            lr = tf.math.maximum(lr_min, lr)\n\n    return lr","metadata":{"execution":{"iopub.status.busy":"2023-10-31T14:17:21.076423Z","iopub.execute_input":"2023-10-31T14:17:21.076678Z","iopub.status.idle":"2023-10-31T14:17:21.087415Z","shell.execute_reply.started":"2023-10-31T14:17:21.076653Z","shell.execute_reply":"2023-10-31T14:17:21.086472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with strategy.scope():\n        \n    \n#     lr_monet_gen = lambda: linear_schedule_with_warmup(tf.cast(monet_generator_optimizer.iterations, tf.float32))\n#     lr_photo_gen = lambda: linear_schedule_with_warmup(tf.cast(photo_generator_optimizer.iterations, tf.float32))\n    \n    monet_generator_optimizer = tf.keras.optimizers.Adam(learning_rate=2e-4, beta_1=0.5)\n    photo_generator_optimizer = tf.keras.optimizers.Adam(learning_rate=2e-4, beta_1=0.5)\n    \n#     lr_monet_disc = lambda: linear_schedule_with_warmup(tf.cast(monet_discriminator_optimizer.iterations, tf.float32))\n#     lr_photo_disc = lambda: linear_schedule_with_warmup(tf.cast(photo_discriminator_optimizer.iterations, tf.float32))\n    \n    monet_discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4, beta_1=0.5)\n    photo_discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4, beta_1=0.5)\n    ","metadata":{"execution":{"iopub.status.busy":"2023-10-31T14:17:21.088339Z","iopub.execute_input":"2023-10-31T14:17:21.088680Z","iopub.status.idle":"2023-10-31T14:17:21.106022Z","shell.execute_reply.started":"2023-10-31T14:17:21.088646Z","shell.execute_reply":"2023-10-31T14:17:21.105119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"with strategy.scope():\n    cycle_gan_model = CycleGan(\n        monet_generator, photo_generator, monet_discriminator, photo_discriminator\n    )\n\n    cycle_gan_model.compile(\n        m_gen_optimizer = monet_generator_optimizer,\n        p_gen_optimizer = photo_generator_optimizer,\n        m_disc_optimizer = monet_discriminator_optimizer,\n        p_disc_optimizer = photo_discriminator_optimizer,\n        gen_loss_fn = generator_loss,\n        disc_loss_fn = discriminator_loss,\n        cycle_loss_fn = calc_cycle_loss,\n        identity_loss_fn = identity_loss\n    )","metadata":{"execution":{"iopub.status.busy":"2023-10-31T14:17:21.107260Z","iopub.execute_input":"2023-10-31T14:17:21.107608Z","iopub.status.idle":"2023-10-31T14:17:21.130424Z","shell.execute_reply.started":"2023-10-31T14:17:21.107580Z","shell.execute_reply":"2023-10-31T14:17:21.129657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = cycle_gan_model.fit(tf.data.Dataset.zip((pws_ds, human_ds)), \n                        epochs=EPOCHS, \n                        steps_per_epoch=max(n_pws_samples, n_human_samples)//BATCH_SIZE).history","metadata":{"execution":{"iopub.status.busy":"2023-10-31T14:17:21.131555Z","iopub.execute_input":"2023-10-31T14:17:21.131829Z","iopub.status.idle":"2023-10-31T14:28:47.383746Z","shell.execute_reply.started":"2023-10-31T14:17:21.131803Z","shell.execute_reply":"2023-10-31T14:28:47.382221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_results_df = pd.DataFrame(history)\nloss_results_df = loss_results_df.applymap(np.mean)\n\n\nplt.plot(loss_results_df.index, loss_results_df['monet_gen_loss'], color='g', label='Loss Monet Generator')\nplt.plot(loss_results_df.index, loss_results_df['photo_gen_loss'], color='r', label='Loss Photo Generator')\nplt.plot(loss_results_df.index, loss_results_df['monet_disc_loss'], color='b', label='Loss Monet Discriminator')\nplt.plot(loss_results_df.index, loss_results_df['photo_disc_loss'], color='m', label='Loss Photo Discriminator')\nplt.legend(loc='best')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-31T14:28:47.384770Z","iopub.status.idle":"2023-10-31T14:28:47.385154Z","shell.execute_reply.started":"2023-10-31T14:28:47.384967Z","shell.execute_reply":"2023-10-31T14:28:47.384985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# _, ax = plt.subplots(5, 2, figsize=(12, 12))\n# for i, img in enumerate(human_ds_test.take(5)):\n#     prediction = monet_generator(img, training=False)[0].numpy()\n#     prediction = (prediction * 127.5 + 127.5).astype(np.uint8)\n#     img = (img[0] * 127.5 + 127.5).numpy().astype(np.uint8)\n\n    \n#     ax[i, 0].imshow(img)\n#     ax[i, 1].imshow(prediction)\n#     ax[i, 0].set_title(\"Input Photo (normal face)\")\n#     ax[i, 1].set_title(\"Face w. PWS\")\n#     ax[i, 0].axis(\"off\")\n#     ax[i, 1].axis(\"off\")\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-31T14:28:47.386756Z","iopub.status.idle":"2023-10-31T14:28:47.387233Z","shell.execute_reply.started":"2023-10-31T14:28:47.387000Z","shell.execute_reply":"2023-10-31T14:28:47.387025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_, ax = plt.subplots(5, 2, figsize=(12, 12))\nfor i, img in enumerate(pws_ds_test.take(5)):\n    prediction = photo_generator(img, training=False)[0].numpy()\n    prediction = (prediction * 127.5 + 127.5).astype(np.uint8)\n    img = (img[0] * 127.5 + 127.5).numpy().astype(np.uint8)\n\n    \n    ax[i, 0].imshow(img)\n    ax[i, 1].imshow(prediction)\n    ax[i, 0].set_title(\"Face w. PWS\")\n    ax[i, 1].set_title(\"Normal Face (output of the model)\")\n    ax[i, 0].axis(\"off\")\n    ax[i, 1].axis(\"off\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-31T14:28:47.388359Z","iopub.status.idle":"2023-10-31T14:28:47.388804Z","shell.execute_reply.started":"2023-10-31T14:28:47.388576Z","shell.execute_reply":"2023-10-31T14:28:47.388599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Save results","metadata":{}},{"cell_type":"code","source":"MODEL_DICT = {\n    \"monet_generator\" : monet_generator,\n    \"photo_generator\" : photo_generator,\n    \"monet_discriminator\" : monet_discriminator,\n     \"photo_discriminator\" : photo_discriminator\n}\n\nfor name, model in MODEL_DICT.items():\n    model.save(f\"{name}.h5\")","metadata":{"execution":{"iopub.status.busy":"2023-10-31T14:28:47.389821Z","iopub.status.idle":"2023-10-31T14:28:47.390254Z","shell.execute_reply.started":"2023-10-31T14:28:47.390026Z","shell.execute_reply":"2023-10-31T14:28:47.390048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import PIL\ntry: \n    ! mkdir ../images \nexcept: pass\ntry: \n    ! mkdir ../images/human-into-pws/ \nexcept: pass\ntry: \n    ! mkdir ../images/pws-into-human/ \nexcept: pass\ntry: \n    ! mkdir /images \nexcept: pass\ntry: \n    ! mkdir /images/human-into-pws/ \nexcept: pass\ntry: \n    ! mkdir /images/pws-into-human/ \nexcept: pass\n\n\n# i = 1\n# for img in human_ds_test:\n#     prediction = monet_generator(img, training=False)[0].numpy()\n#     prediction = (prediction * 127.5 + 127.5).astype(np.uint8)\n#     im = PIL.Image.fromarray(prediction)\n#     im.save(\"../images/human-into-pws/\" + str(i) + \".jpg\")\n#     i += 1\n#     if i==200:\n#         break\n    \nfor img in pws_ds_test:\n    prediction = photo_generator(img, training=False)[0].numpy()\n    prediction = (prediction * 127.5 + 127.5).astype(np.uint8)\n    im = PIL.Image.fromarray(prediction)\n    im.save(\"../images/pws-into-human/\" + str(i) + \".jpg\")\n    print(f\"i: {i}\")\n    i += 1\n    \n    \n    \nimport shutil\n# shutil.make_archive(\"/kaggle/working/images/human-into-pws/\", 'zip', \"/kaggle/images\")\nshutil.make_archive(\"/kaggle/working/images/pws-into-human/\", 'zip', \"/kaggle/images\")","metadata":{"execution":{"iopub.status.busy":"2023-10-31T14:28:47.391694Z","iopub.status.idle":"2023-10-31T14:28:47.392163Z","shell.execute_reply.started":"2023-10-31T14:28:47.391902Z","shell.execute_reply":"2023-10-31T14:28:47.391925Z"},"trusted":true},"execution_count":null,"outputs":[]}]}